{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.conda/lib/python3.10/site-packages (1.24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in ./.conda/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: numpy>=1.20 in ./.conda/lib/python3.10/site-packages (from matplotlib) (1.24.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.conda/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.conda/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.conda/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.conda/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.10/site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./.conda/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./.conda/lib/python3.10/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in ./.conda/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./.conda/lib/python3.10/site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./.conda/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the following packages in the environment\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv', header=None)\n",
    "train_label_data = pd.read_csv('data/trainLabels.csv', header=None)\n",
    "\n",
    "X = train_data\n",
    "y = train_label_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# See if there are any missing values\n",
    "missing_val_count_by_column = (X.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0  0.299403 -1.226624  1.498425 -1.176150  5.289853  0.208297  2.404498   \n",
      "1 -1.174176  0.332157  0.949919 -1.285328  2.199061 -0.151268 -0.427039   \n",
      "2  1.192222 -0.414371  0.067054 -2.233568  3.658881  0.089007  0.203439   \n",
      "3  1.573270 -0.580318 -0.866332 -0.603812  3.125716  0.870321 -0.161992   \n",
      "4 -0.613071 -0.644204  1.112558 -0.032397  3.490142 -0.011935  1.443521   \n",
      "\n",
      "         7         8         9   ...        30        31        32        33  \\\n",
      "0  1.594506 -0.051608  0.663234  ... -0.850465 -0.622990 -1.833057  0.293024   \n",
      "1  2.619246 -0.765884 -0.093780  ... -0.819750  0.012037  2.038836  0.468579   \n",
      "2 -4.219054 -1.184919 -1.240310  ... -0.604501  0.750054 -3.360521  0.856988   \n",
      "3  4.499666  1.038741 -1.092716  ...  1.022959  1.275598 -3.480110 -1.065252   \n",
      "4 -4.290282 -1.761308  0.807652  ...  0.513906 -1.803473  0.518579 -0.205029   \n",
      "\n",
      "         34        35        36        37        38        39  \n",
      "0  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n",
      "1 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n",
      "2 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n",
      "3  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n",
      "4 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# Explore the data\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1000, 41)\n",
      "Shape after removing outliers: (747, 41)\n"
     ]
    }
   ],
   "source": [
    "labeled_y = y.copy()\n",
    "labeled_y.columns = ['Result']\n",
    "full = pd.concat([X, labeled_y], axis=1)\n",
    "print(f\"Original shape: {full.shape}\")\n",
    "\n",
    "# https://www.scribbr.com/statistics/outliers/\n",
    "# Remove outliers\n",
    "for col in full.columns:\n",
    "    if col == 'Result':\n",
    "        continue\n",
    "    q1 = full[col].quantile(0.25)\n",
    "    q3 = full[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    threshold = 1.5 * iqr\n",
    "    # Remove rows that are outliers\n",
    "    full = full[(full[col] >= q1 - threshold) & (full[col] <= q3 + threshold)] \n",
    "    \n",
    "print(f\"Shape after removing outliers: {full.shape}\")\n",
    "\n",
    "new_y = full['Result']\n",
    "new_X = full.drop('Result', axis=1)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(\n",
    "    new_X, new_y,\n",
    "    train_size=0.8, test_size=0.2,\n",
    "    random_state=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__n_estimators': 400}\n",
      "Best score:  0.8609803921568627\n"
     ]
    }
   ],
   "source": [
    "# Find hyperparameters with grid search\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': range(100, 550, 100),\n",
    "    'classifier__max_depth': range(1, 20, 10),\n",
    "    'classifier__min_samples_leaf': range(1, 4, 1),\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "# grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_absolute_error')\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train_full, y_train.values.ravel())\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean cross-validated score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# scores = {}\n",
    "# for n_estimators in range(100, 550, 50):\n",
    "#     model = RandomForestClassifier(n_estimators, random_state=0)\n",
    "#     piepline = Pipeline(steps=[\n",
    "#         ('model', model)\n",
    "#     ])\n",
    "#     mean_score = -1 * cross_val_score(\n",
    "#         piepline, X, y.values.ravel(), cv=5, scoring='neg_mean_absolute_error').mean()\n",
    "#     scores[n_estimators] = mean_score\n",
    "#     print(f\"n_estimators: {n_estimators}, mean_score: {mean_score}\")\n",
    "\n",
    "# print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66  7]\n",
      " [14 63]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Break off validation set from training data\n",
    "# X_train_full, X_valid_full, y_train, y_valid = train_test_split(\n",
    "#     X, y,\n",
    "#     train_size=0.8, test_size=0.2,\n",
    "#     random_state=0\n",
    "# )\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = RandomForestClassifier(n_estimators=400, max_depth=11, min_samples_leaf=2, random_state=0)\n",
    "\n",
    "piepline = Pipeline(steps=[\n",
    "    ('scaler', scaler),\n",
    "    ('model', model)\n",
    "])\n",
    "piepline.fit(X_train_full, y_train.values.ravel())\n",
    "cmatrix = confusion_matrix(y_valid, model.predict(X_valid_full))\n",
    "print(cmatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db680ce667160fc9f7b1e6471308e5c3fc6e79bb9c2205bd13fa5f5666a314d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
